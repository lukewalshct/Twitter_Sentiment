
#mark all words with negation
all_words_neg = sentim_analyzer.all_words([mark_negation(doc) for doc in train_data_sample])

#filter out stopwords
all_words_neg_nostops = [x for x in all_words_neg if x not in stopwords_all]

#extract top too words as unigram features
unigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg_nostops, top_n=200)
sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)

#apply features and train the model
training_set = sentim_analyzer.apply_features(train_data_sample)
trainer = NaiveBayesClassifier.train
classifier = sentim_analyzer.train(trainer, training_set)


#set up authorization - key/token/secrets can be retrieved from 
#your Twitter developer account
auth = requests_oauthlib.OAuth1(key, secret, token, token_secret)

#example GET request made to the Twitter stream
search_term='Trump'
filter_url = 'https://stream.twitter.com/1.1/statuses/filter.json?track='+search_term
response = requests.get(filter_url, auth=auth, stream=True)